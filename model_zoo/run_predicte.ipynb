{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U segmentation-models-pytorch albumentations --user\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "import linzhutils as lu\n",
    "import tqdm\n",
    "import torch\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/scratch/project_2007251/2019/hel2019/'\n",
    "\n",
    "IMAGE_DIR = 'output'\n",
    "img_dir = os.path.join(DATA_DIR, IMAGE_DIR)\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2, 0, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "model = torch.load('./models/kussi_FPN_efficientnet-b7_7_0.490.pth')\n",
    "# ENCODER = 'efficientnet-b7'\n",
    "# ENCODER_WEIGHTS = 'imagenet'\n",
    "# CLASSES = ['kussi']\n",
    "batch_size = 128\n",
    "input_batch = []\n",
    "mask_batch = []\n",
    "result_masks = []\n",
    "total_size = 0\n",
    "file_num = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList=lu.getFileList(img_dir)\n",
    "for i in range(len(fileList)):\n",
    "    fileList[i] = os.path.join(img_dir, fileList[i])\n",
    "fileList = sorted(fileList)\n",
    "# np.save('/scratch/project_2007251/2019/results/file_list.npy',np.array(fileList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 533/50400 [00:27<42:35, 19.51it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     file_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(fileList))):\n\u001b[0;32m---> 11\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileList\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     13\u001b[0m     input_batch\u001b[38;5;241m.\u001b[39mappend(to_tensor(image))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def save_masks(masks):\n",
    "    global file_num\n",
    "    filename = f\"/scratch/project_2007251/2019/results/result_masks_{file_num}.npy\"\n",
    "    concatenated = np.concatenate(masks, axis=0)\n",
    "    reshaped = concatenated.reshape((-1, 512, 512))\n",
    "    np.save(filename, np.array(masks))\n",
    "    print(f\"Saved {filename}\")\n",
    "    file_num += 1\n",
    "\n",
    "for i in tqdm.tqdm(range(len(fileList))):\n",
    "    image = cv2.imread(fileList[i])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    input_batch.append(to_tensor(image))\n",
    "\n",
    "    if len(input_batch) == batch_size:\n",
    "        x_tensor = torch.from_numpy(np.array(input_batch)).to(DEVICE)\n",
    "        # print(x_tensor.shape)\n",
    "        pr_mask_batch = model.predict(x_tensor).squeeze().cpu().numpy().round()\n",
    "        result_masks.append(pr_mask_batch)\n",
    "        total_size += pr_mask_batch.nbytes\n",
    "\n",
    "        if total_size > 1e9:\n",
    "            save_masks(result_masks)\n",
    "            result_masks = []\n",
    "            total_size = 0\n",
    "\n",
    "        input_batch = []\n",
    "        mask_batch = []\n",
    "save_masks(result_masks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# # helper function for data visualization\n",
    "# def visualize(**images):\n",
    "#     \"\"\"PLot images in one row.\"\"\"\n",
    "#     n = len(images)\n",
    "#     plt.figure(figsize=(16, 5))\n",
    "#     for i, (name, image) in enumerate(images.items()):\n",
    "#         plt.subplot(1, n, i + 1)\n",
    "#         plt.xticks([])\n",
    "#         plt.yticks([])\n",
    "#         plt.title(' '.join(name.split('_')).title())\n",
    "#         plt.imshow(image)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 129/90000 [00:12<2:22:43, 10.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "batch_size = 1\n",
    "input_batch = []\n",
    "mask_batch = []\n",
    "images_list = []\n",
    "result_masks = []\n",
    "total_size = 0\n",
    "file_num = 0\n",
    "start_index = 10000\n",
    "\n",
    "for i in tqdm.tqdm(range(start_index, 100000)):\n",
    "    image = cv2.imread(fileList[i])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    images_list.append(image)\n",
    "    input_batch.append(to_tensor(image))\n",
    "\n",
    "    # if len(input_batch) == batch_size:\n",
    "    x_tensor = torch.from_numpy(np.array(input_batch)).to(DEVICE)\n",
    "    pr_mask_batch = model.predict(x_tensor).squeeze().cpu().numpy().round()\n",
    "    result_masks.append(pr_mask_batch)\n",
    "    input_batch = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images_list)):\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(images_list[i])\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(result_masks[i])\n",
    "    plt.show()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result_masks[0])):\n",
    "    plt.figure()\n",
    "    \n",
    "    plt.imshow(result_masks[0][i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# # load the image and mask lists\n",
    "# images = np.array(input_batch)\n",
    "# masks = pr_mask_batch\n",
    "\n",
    "# # plot the images and masks\n",
    "\n",
    "# for i in range(images.shape[0]):\n",
    "#     # create a figure with two subplots\n",
    "#     fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "#     # plot the image\n",
    "#     axs[0].imshow(images[i][0])\n",
    "#     axs[0].axis('off')\n",
    "#     axs[0].set_title('Image {}'.format(i+1))\n",
    "    \n",
    "#     # plot the mask\n",
    "#     axs[1].imshow(masks[i]*255, cmap='gray')\n",
    "#     axs[1].axis('off')\n",
    "#     axs[1].set_title('Mask {}'.format(i+1))\n",
    "    \n",
    "#     # show the figure\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtest_dataset\u001b[49m))\n\u001b[1;32m      6\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      8\u001b[0m     image_vis \u001b[38;5;241m=\u001b[39m test_dataset_vis[n][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# import time\n",
    "\n",
    "# for i in range(20):\n",
    "#     n = np.random.choice(len(test_dataset))\n",
    "\n",
    "#     t1 = time.time()\n",
    "    \n",
    "#     image_vis = test_dataset_vis[n][0].astype('uint8')\n",
    "#     image, gt_mask = test_dataset[n]\n",
    "\n",
    "#     gt_mask = gt_mask.squeeze()\n",
    "\n",
    "#     x_tensor = torch.from_numpy(image).to(DEVICE).unsqueeze(0)\n",
    "#     pr_mask = model.predict(x_tensor)\n",
    "#     pr_mask = (pr_mask.squeeze().cpu().numpy().round())\n",
    "\n",
    "#     print(time.time()-t1)\n",
    "    \n",
    "#     visualize(image=image_vis,\n",
    "#               ground_truth_mask=gt_mask,\n",
    "#               predicted_mask=pr_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
